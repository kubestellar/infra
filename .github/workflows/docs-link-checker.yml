name: Docs Link Checker

on:
  schedule:
    - cron: '0 6 * * 1'  # Every Monday at 6 AM UTC
  workflow_dispatch:

permissions:
  contents: read

jobs:
  check-links:
    runs-on: ubuntu-latest
    steps:
      - name: Check links on all documentation sites
        id: check
        env:
          GH_TOKEN: ${{ secrets.WORKFLOW_SYNC_TOKEN }}
        run: |
          set -euo pipefail

          # Install lychee link checker
          curl -sLO https://github.com/lycheeverse/lychee/releases/download/v0.15.1/lychee-v0.15.1-x86_64-unknown-linux-gnu.tar.gz
          tar xzf lychee-v0.15.1-x86_64-unknown-linux-gnu.tar.gz
          chmod +x lychee

          # Create output directory
          mkdir -p results

          # Function to run lychee with common options
          run_lychee() {
            local output_file="$1"
            local url="$2"
            ./lychee --no-progress --format json --output "$output_file" \
              --exclude 'github.com.*edit' \
              --exclude 'linkedin.com' \
              --exclude 'twitter.com' \
              --exclude 'x.com' \
              --exclude 'slack.com' \
              --exclude 'forms.gle' \
              --exclude 'localhost' \
              --exclude '127.0.0.1' \
              --exclude 'blog.kubestellar.io' \
              --max-redirects 10 \
              --max-concurrency 2 \
              --timeout 60 \
              --retry-wait-time 10 \
              --max-retries 5 \
              --user-agent "Mozilla/5.0 (compatible; KubeStellarLinkChecker/1.0)" \
              "$url" || true
          }

          # Check kubestellar.io main site (landing page)
          echo "=== Checking kubestellar.io (main site) ==="
          run_lychee "results/main.json" "https://kubestellar.io"

          # Check KubeStellar docs
          echo "=== Checking kubestellar.io/docs (KubeStellar docs) ==="
          run_lychee "results/kubestellar-docs.json" "https://kubestellar.io/docs"

          # Check a2a docs
          echo "=== Checking kubestellar.io/docs/a2a (A2A docs) ==="
          run_lychee "results/a2a-docs.json" "https://kubestellar.io/docs/a2a"

          # Check kubeflex docs
          echo "=== Checking kubestellar.io/docs/kubeflex (KubeFlex docs) ==="
          run_lychee "results/kubeflex-docs.json" "https://kubestellar.io/docs/kubeflex"

          # Check multi-plugin docs
          echo "=== Checking kubestellar.io/docs/multi-plugin (Multi-Plugin docs) ==="
          run_lychee "results/multi-plugin-docs.json" "https://kubestellar.io/docs/multi-plugin"

          # Combine and extract errors
          echo "=== Processing results ==="
          cat results/*.json 2>/dev/null | jq -s 'add' > results/combined.json || echo '{"fail_map":{}}' > results/combined.json

          # Extract failed URLs with status and source pages
          # In lychee's fail_map: key = source page, value[].url = broken URL
          jq -r '.fail_map // {} | to_entries[] | .key as $source | .value[] | "\(.url)|\(.status // "unknown")|\($source)"' results/combined.json > results/broken_links.txt || touch results/broken_links.txt

          # Create a list of broken URL hashes for comparison
          while IFS='|' read -r url status source; do
            [ -z "$url" ] && continue
            echo "$url" | md5sum | cut -c1-8
          done < results/broken_links.txt > results/broken_hashes.txt

          echo "=== Broken links found ==="
          cat results/broken_links.txt || echo "None"

          # Count broken links
          broken_count=$(wc -l < results/broken_links.txt | tr -d ' ')
          echo "broken_count=$broken_count" >> $GITHUB_OUTPUT
          echo "Total broken links: $broken_count"

      - name: Close fixed link issues
        env:
          GH_TOKEN: ${{ secrets.WORKFLOW_SYNC_TOKEN }}
        run: |
          set -euo pipefail

          echo "Checking for issues with fixed links..."

          # Get all open issues with "Broken link:" in the title
          gh issue list --repo kubestellar/docs \
            --search "Broken link: in:title" \
            --state open \
            --json number,title,body \
            --limit 100 > results/open_issues.json || echo "[]" > results/open_issues.json

          # Process each open issue
          jq -c '.[]' results/open_issues.json | while read -r issue; do
            number=$(echo "$issue" | jq -r '.number')
            title=$(echo "$issue" | jq -r '.title')
            body=$(echo "$issue" | jq -r '.body')

            # Extract the hash from the issue body
            issue_hash=$(echo "$body" | grep -oP '(?<=Hash:\*\* )[a-f0-9]+' || echo "")

            if [ -z "$issue_hash" ]; then
              echo "Could not find hash in issue #$number, skipping"
              continue
            fi

            # Check if this hash is still in our broken links
            if grep -q "^${issue_hash}$" results/broken_hashes.txt 2>/dev/null; then
              echo "Issue #$number: Link still broken (hash: $issue_hash)"
            else
              echo "Issue #$number: Link appears to be fixed, closing..."
              close_comment=$(printf '%s\n\n%s' \
                "This link appears to be fixed! Verified by the automated link checker." \
                "If this was closed in error, please reopen the issue.")
              gh issue close "$number" --repo kubestellar/docs \
                --comment "$close_comment" || echo "Failed to close issue #$number"
              sleep 1
            fi
          done

          echo "Done checking for fixed links"

      - name: Create issues for broken links
        if: steps.check.outputs.broken_count > 0
        env:
          GH_TOKEN: ${{ secrets.WORKFLOW_SYNC_TOKEN }}
        run: |
          set -euo pipefail

          # Check each broken link and create issue if not already exists
          while IFS='|' read -r url status source; do
            [ -z "$url" ] && continue

            # Create a unique identifier for the issue
            url_hash=$(echo "$url" | md5sum | cut -c1-8)
            issue_title="Broken link: $(echo "$url" | cut -c1-70)..."

            # Check if issue already exists (open)
            existing=$(gh issue list --repo kubestellar/docs \
              --search "Hash:** $url_hash in:body" \
              --state open \
              --json number \
              --jq '.[0].number' 2>/dev/null || echo "")

            if [ -n "$existing" ] && [ "$existing" != "null" ]; then
              echo "Issue already exists for $url (issue #$existing)"
              continue
            fi

            # Create new issue
            echo "Creating issue for broken link: $url (status: $status, source: $source)"
            issue_body=$(printf '## Broken Link Detected\n\n**Broken URL:** [%s](%s)\n**Status:** %s\n**Found on page:** [%s](%s)\n**Hash:** %s\n\n### How to fix\n1. Go to the source page listed above\n2. Find and update the broken link to a working URL, or remove it if no longer relevant\n3. Submit a PR with the fix\n\n---\nAuto-generated by [docs-link-checker](https://github.com/kubestellar/infra/actions/workflows/docs-link-checker.yml)' "$url" "$url" "$status" "$source" "$source" "$url_hash")
            issue_url=$(gh issue create --repo kubestellar/docs \
              --title "$issue_title" \
              --body "$issue_body") || { echo "Failed to create issue for $url"; continue; }

            # Add labels separately (sometimes inline options don't work)
            issue_num=$(echo "$issue_url" | grep -oE '[0-9]+$')
            if [ -n "$issue_num" ]; then
              gh issue edit "$issue_num" --repo kubestellar/docs \
                --add-label "help wanted" \
                --add-label "good first issue" \
                --add-label "bug" \
                --add-label "documentation" || echo "Failed to add labels to issue #$issue_num"
            fi

            # Rate limit to avoid API issues
            sleep 2
          done < results/broken_links.txt

          echo "Done processing broken links"
